load("~/Development/DAX/.RData")
plot(dax.sorted,col="blue", xlab="Year", ylab="DAX Value")
p.qrt <- filter(p,filter=rep(1/20,20))
lines(p.qrt,col="red")
lines(reg$fitted.values)
lines(pred$pred,col="green")
dax <- read.csv("~/Development/DAX/table.csv")
library("zoo", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
dax.sorted <- dax[order(as.Date(dax$Date, format="%Y-%m-%d")),]
d <- dax.sorted$Date
p <- dax.sorted$Close
dax.sorted <- zoo(p, order.by = d)
# Regression
d <- as.Date(d, format="%Y-%m-%d")
d.ms <- as.numeric(d) * 86400000
d.ms2 <- d.ms^2
reg <- lm(p~ d.ms2)
summary(reg)
# ARIMA model
par(mfrow = c(1,2))
acf(p)
pacf(p)
par(mfrow=c(1,1))
fit <- arima(p,c(0,1,1))
pred <- predict(fit,n.ahead=250)
# Graphical representation
plot(dax.sorted,col="blue", xlab="Year", ylab="DAX Value")
p.qrt <- filter(p,filter=rep(1/20,20))
lines(p.qrt,col="red")
lines(reg$fitted.values)
lines(pred$pred,col="green")
dax <- read.csv("~/Development/DAX/sp500.csv")
library("zoo", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
dax.sorted <- dax[order(as.Date(dax$Date, format="%Y-%m-%d")),]
d <- dax.sorted$Date
p <- dax.sorted$Close
dax.sorted <- zoo(p, order.by = d)
# Regression
d <- as.Date(d, format="%Y-%m-%d")
d.ms <- as.numeric(d) * 86400000
d.ms2 <- d.ms^2
reg <- lm(p~ d.ms2)
summary(reg)
# ARIMA model
par(mfrow = c(1,2))
acf(p)
pacf(p)
par(mfrow=c(1,1))
fit <- arima(p,c(0,1,1))
pred <- predict(fit,n.ahead=250)
# Graphical representation
plot(dax.sorted,col="blue", xlab="Year", ylab="DAX Value")
p.qrt <- filter(p,filter=rep(1/20,20))
lines(p.qrt,col="red")
lines(reg$fitted.values)
lines(pred$pred,col="green")
2**2
100 * ((1.025)**(1/30))
100 * ((1.025)**(30))
2.5 * 30
45/30
75/30
5 * (100000/180)
load("~/Development/bads-challenge/.RData")
# Ensemble with xgboost,rf, nnet and a logistic regresission stacking model
pred.xgb <- predict(xgbFit,test.sample, type="prob")["leave"]
pred.nn <- predict(nnFit,test.sample, type="prob")["leave"]
pred.rf <- predict(rfFit,test.sample, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb.1$leave,second=pred.xgb.2$leave,third=pred.xgb.3$leave) # combine to dataframe
# Learn the regression
lrFit.stacked.model <- train(test.sample$churn ~ ., data = model.ensemble,method = "plr",trControl = fitControl, metric="ROC")
# predict on validation set
pred.stack.lr.model <- predict(lrFit.stacked.model,validation.sample, type="prob")["leave"]
performance(pred.stack.lr.model$leave,validation.sample$churn)
library("caret", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
library("pROC", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
# Ensemble with xgboost,rf, nnet and a logistic regresission stacking model
pred.xgb <- predict(xgbFit,test.sample, type="prob")["leave"]
pred.nn <- predict(nnFit,test.sample, type="prob")["leave"]
pred.rf <- predict(rfFit,test.sample, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb.1$leave,second=pred.xgb.2$leave,third=pred.xgb.3$leave) # combine to dataframe
# Learn the regression
lrFit.stacked.model <- train(test.sample$churn ~ ., data = model.ensemble,method = "plr",trControl = fitControl, metric="ROC")
# predict on validation set
pred.stack.lr.model <- predict(lrFit.stacked.model,validation.sample, type="prob")["leave"]
performance(pred.stack.lr.model$leave,validation.sample$churn)
model.ensemble <- data.frame(first=pred.xgb.1$leave,second=pred.xgb.2$leave,third=pred.xgb.3$leave) # combine to dataframe
# Learn the regression
lrFit.stacked.model <- train(test.sample$churn ~ ., data = model.ensemble,method = "plr",trControl = fitControl, metric="ROC")
pred.xgb <- predict(xgbFit,test.sample, type="prob")["leave"]
pred.nn <- predict(nnFit,test.sample, type="prob")["leave"]
pred.rf <- predict(rfFit,test.sample, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb.1$leave,second=pred.xgb.2$leave,third=pred.xgb.3$leave) # combine to dataframe
model.ensemble <- data.frame(first=pred.xgb$leave,second=pred.nn$leave,third=pred.rf$leave) # combine to dataframe
# Learn the regression
lrFit.stacked.model <- train(test.sample$churn ~ ., data = model.ensemble,method = "plr",trControl = fitControl, metric="ROC")
# predict on validation set
pred.stack.lr.model <- predict(lrFit.stacked.model,validation.sample, type="prob")["leave"]
pred.xgb <- predict(xgbFit,validation.sample, type="prob")["leave"]
pred.nn <- predict(nnFit,validation.sample, type="prob")["leave"]
pred.rf <- predict(rfFit,validation.sample, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb$leave,second=pred.nn$leave,third=pred.rf$leave) # combine to dataframe
pred.stack.lr.model <- predict(lrFit.stacked.model,mode.ensemble, type="prob")["leave"]
performance(pred.stack.lr.model$leave,validation.sample$churn)
pred.stack.lr.model <- predict(lrFit.stacked.model,model.ensemble, type="prob")["leave"]
performance(pred.stack.lr.model$leave,validation.sample$churn)
pred.xgb <- predict(xgbFit,dataset.final, type="prob")["leave"]
pred.nn <- predict(nnFit,dataset.final, type="prob")["leave"]
pred.rf <- predict(rfFit,dataset.final, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb$leave,second=pred.nn$leave,third=pred.rf$leave) # combine to dataframe
pred.stack.lr.model <- predict(lrFit.stacked.model,model.ensemble, type="prob")["leave"]
performance(pred.stack.lr.model$leave,dataset.final$churn)
x <- data.frame(Customer_ID=ids,EstimatedChurnProbability=pred.xgb.prob$leave)
write.table(x,"sub_3_models.csv",sep=",",row.names=FALSE)
performance(pred.stack.lr.model$leave,dataset.final$churn)
# Load the data
dataset <- read.csv2("data/training.csv",sep=",", stringsAsFactors = FALSE)
# Functions for data prep
source("encodeFeatures.R")
source("performance.R")
# Encode data as dummies and numeric
names(dataset) <- toupper(names(dataset))
dataset <- encodeFeatures(dataset)
# All the numerical features from the spreadsheet. All usage based
numerical_features <-c("ADJMOU","ADJQTY","ADJREV","ATTEMPT_MEAN","ATTEMPT_RANGE","AVG3MOU","AVG3QTY","AVG3REV","AVG6MOU","AVG6QTY","AVG6REV","AVGMOU","AVGQTY","AVGREV","BLCK_DAT_MEAN","BLCK_DAT_RANGE","BLCK_VCE_MEAN","BLCK_VCE_RANGE","CALLFWDV_MEAN","CALLFWDV_RANGE","CALLWAIT_MEAN","CALLWAIT_RANGE","CC_MOU_MEAN","CC_MOU_RANGE","CCRNDMOU_MEAN","CCRNDMOU_RANGE","CHANGE_MOU","CHANGE_REV","COMP_DAT_MEAN","COMP_DAT_RANGE","COMP_VCE_MEAN","COMP_VCE_RANGE","COMPLETE_MEAN","COMPLETE_RANGE","CUSTCARE_MEAN","CUSTCARE_RANGE","DA_MEAN","DA_RANGE","DATOVR_MEAN","DATOVR_RANGE","DROP_BLK_MEAN","DROP_BLK_RANGE","DROP_DAT_MEAN","DROP_DAT_RANGE","DROP_VCE_MEAN","DROP_VCE_RANGE","EQPDAYS","INONEMIN_MEAN","INONEMIN_RANGE","IWYLIS_VCE_MEAN","IWYLIS_VCE_RANGE","MONTHS","MOU_CDAT_MEAN","MOU_CDAT_RANGE","MOU_CVCE_MEAN","MOU_CVCE_RANGE","MOU_MEAN","MOU_OPKD_MEAN","MOU_OPKD_RANGE","MOU_OPKV_MEAN","MOU_OPKV_RANGE","MOU_PEAD_MEAN","MOU_PEAD_RANGE","MOU_PEAV_MEAN","MOU_PEAV_RANGE","MOU_RANGE","MOU_RVCE_MEAN","MOU_RVCE_RANGE","MOUIWYLISV_MEAN","MOUIWYLISV_RANGE","MOUOWYLISV_MEAN","MOUOWYLISV_RANGE","OWYLIS_VCE_MEAN","OWYLIS_VCE_RANGE","OPK_DAT_MEAN","OPK_DAT_RANGE","OPK_VCE_MEAN","OPK_VCE_RANGE","OVRMOU_MEAN","OVRMOU_RANGE","OVRREV_MEAN","OVRREV_RANGE","PEAK_DAT_MEAN","PEAK_DAT_RANGE","PEAK_VCE_MEAN","PEAK_VCE_RANGE","PLCD_DAT_MEAN","PLCD_DAT_RANGE","PLCD_VCE_MEAN","PLCD_VCE_RANGE","RECV_SMS_MEAN","RECV_SMS_RANGE","RECV_VCE_MEAN","RECV_VCE_RANGE","RETDAYS","REV_MEAN","REV_RANGE","RMCALLS","RMMOU","RMREV","ROAM_MEAN","ROAM_RANGE","THREEWAY_MEAN","THREEWAY_RANGE","TOTCALLS","TOTMOU","TOTMRC_MEAN","TOTMRC_RANGE","TOTREV","UNAN_DAT_MEAN","UNAN_DAT_RANGE","UNAN_VCE_MEAN","UNAN_VCE_RANGE","VCEOVR_MEAN","VCEOVR_RANGE")
# impute the data
source('imputeData.R')
#select features
source("selectFeatures.R")
setwd("~/Development/bads-challenge")
# Load the data
dataset <- read.csv2("data/training.csv",sep=",", stringsAsFactors = FALSE)
# Functions for data prep
source("encodeFeatures.R")
source("performance.R")
# Encode data as dummies and numeric
names(dataset) <- toupper(names(dataset))
dataset <- encodeFeatures(dataset)
# All the numerical features from the spreadsheet. All usage based
numerical_features <-c("ADJMOU","ADJQTY","ADJREV","ATTEMPT_MEAN","ATTEMPT_RANGE","AVG3MOU","AVG3QTY","AVG3REV","AVG6MOU","AVG6QTY","AVG6REV","AVGMOU","AVGQTY","AVGREV","BLCK_DAT_MEAN","BLCK_DAT_RANGE","BLCK_VCE_MEAN","BLCK_VCE_RANGE","CALLFWDV_MEAN","CALLFWDV_RANGE","CALLWAIT_MEAN","CALLWAIT_RANGE","CC_MOU_MEAN","CC_MOU_RANGE","CCRNDMOU_MEAN","CCRNDMOU_RANGE","CHANGE_MOU","CHANGE_REV","COMP_DAT_MEAN","COMP_DAT_RANGE","COMP_VCE_MEAN","COMP_VCE_RANGE","COMPLETE_MEAN","COMPLETE_RANGE","CUSTCARE_MEAN","CUSTCARE_RANGE","DA_MEAN","DA_RANGE","DATOVR_MEAN","DATOVR_RANGE","DROP_BLK_MEAN","DROP_BLK_RANGE","DROP_DAT_MEAN","DROP_DAT_RANGE","DROP_VCE_MEAN","DROP_VCE_RANGE","EQPDAYS","INONEMIN_MEAN","INONEMIN_RANGE","IWYLIS_VCE_MEAN","IWYLIS_VCE_RANGE","MONTHS","MOU_CDAT_MEAN","MOU_CDAT_RANGE","MOU_CVCE_MEAN","MOU_CVCE_RANGE","MOU_MEAN","MOU_OPKD_MEAN","MOU_OPKD_RANGE","MOU_OPKV_MEAN","MOU_OPKV_RANGE","MOU_PEAD_MEAN","MOU_PEAD_RANGE","MOU_PEAV_MEAN","MOU_PEAV_RANGE","MOU_RANGE","MOU_RVCE_MEAN","MOU_RVCE_RANGE","MOUIWYLISV_MEAN","MOUIWYLISV_RANGE","MOUOWYLISV_MEAN","MOUOWYLISV_RANGE","OWYLIS_VCE_MEAN","OWYLIS_VCE_RANGE","OPK_DAT_MEAN","OPK_DAT_RANGE","OPK_VCE_MEAN","OPK_VCE_RANGE","OVRMOU_MEAN","OVRMOU_RANGE","OVRREV_MEAN","OVRREV_RANGE","PEAK_DAT_MEAN","PEAK_DAT_RANGE","PEAK_VCE_MEAN","PEAK_VCE_RANGE","PLCD_DAT_MEAN","PLCD_DAT_RANGE","PLCD_VCE_MEAN","PLCD_VCE_RANGE","RECV_SMS_MEAN","RECV_SMS_RANGE","RECV_VCE_MEAN","RECV_VCE_RANGE","RETDAYS","REV_MEAN","REV_RANGE","RMCALLS","RMMOU","RMREV","ROAM_MEAN","ROAM_RANGE","THREEWAY_MEAN","THREEWAY_RANGE","TOTCALLS","TOTMOU","TOTMRC_MEAN","TOTMRC_RANGE","TOTREV","UNAN_DAT_MEAN","UNAN_DAT_RANGE","UNAN_VCE_MEAN","UNAN_VCE_RANGE","VCEOVR_MEAN","VCEOVR_RANGE")
# impute the data
source('imputeData.R')
#select features
source("selectFeatures.R")
# 3 model ensemble
pred.xgb <- predict(xgbFit,dataset.final, type="prob")["leave"]
pred.nn <- predict(nnFit,dataset.final, type="prob")["leave"]
pred.rf <- predict(rfFit,dataset.final, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb$leave,second=pred.nn$leave,third=pred.rf$leave) # combine to dataframe
pred.stack.lr.model <- predict(lrFit.stacked.model,model.ensemble, type="prob")["leave"]
performance(pred.stack.lr.model$leave,dataset.final$churn)
x <- data.frame(Customer_ID=ids,EstimatedChurnProbability=pred.xgb.prob$leave)
write.table(x,"sub_3_models.csv",sep=",",row.names=FALSE)
lrFit.stacked.model
suammry(lrFit.stacked.model)
summary(lrFit.stacked.model)
View(x)
write.table(x,"sub_3_models.csv",sep=",",row.names=FALSE)
x <- cbind(x,dataset.final$churn)
x <- x[with(x,order(-EstimatedChurnProbability)),]
View(x)
performance(pred.stack.lr.model$leave,validation.sample$churn)
# predict on validation set
pred.xgb <- predict(xgbFit,validation.sample, type="prob")["leave"]
pred.nn <- predict(nnFit,validation.sample, type="prob")["leave"]
pred.rf <- predict(rfFit,validation.sample, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb$leave,second=pred.nn$leave,third=pred.rf$leave) # combine to dataframe
pred.stack.lr.model <- predict(lrFit.stacked.model,model.ensemble, type="prob")["leave"]
performance(pred.stack.lr.model$leave,validation.sample$churn)
usedDataset <- dataset.final#[sample(c(1:nrow(dataset.final)),round(nrow(dataset.final))*0.8),]
index <- c(1:nrow(usedDataset))
trainingData <- sample(index,round(nrow(usedDataset))*0.8)
test <- usedDataset[-trainingData,]
training <- usedDataset[trainingData,]
# delete the temp datasets
remove(trainingData)
remove(usedDataset)
index <- c(1:nrow(test))
testData <- sample(index,round(nrow(test))*0.8)
test.sample <- test[testData,]
validation.sample <-test[-testData,]
pred.xgb <- predict(xgbFit,validation.sample, type="prob")["leave"]
pred.nn <- predict(nnFit,validation.sample, type="prob")["leave"]
pred.rf <- predict(rfFit,validation.sample, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb$leave,second=pred.nn$leave,third=pred.rf$leave) # combine to dataframe
pred.stack.lr.model <- predict(lrFit.stacked.model,model.ensemble, type="prob")["leave"]
performance(pred.stack.lr.model$leave,validation.sample$churn)
usedDataset <- dataset.final#[sample(c(1:nrow(dataset.final)),round(nrow(dataset.final))*0.8),]
index <- c(1:nrow(usedDataset))
trainingData <- sample(index,round(nrow(usedDataset))*0.8)
test <- usedDataset[-trainingData,]
training <- usedDataset[trainingData,]
# delete the temp datasets
remove(trainingData)
remove(usedDataset)
validation.sample <- test
pred.xgb <- predict(xgbFit,validation.sample, type="prob")["leave"]
pred.nn <- predict(nnFit,validation.sample, type="prob")["leave"]
pred.rf <- predict(rfFit,validation.sample, type="prob")["leave"]
model.ensemble <- data.frame(first=pred.xgb$leave,second=pred.nn$leave,third=pred.rf$leave) # combine to dataframe
pred.stack.lr.model <- predict(lrFit.stacked.model,model.ensemble, type="prob")["leave"]
performance(pred.stack.lr.model$leave,validation.sample$churn)
